{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBmBddzzGjrQ+62DS/Lf6Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zmbq/butbul-halacha-ingest/blob/main/research/butbul_halacha_find_categories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load all the data from the database, prepare for analysis"
      ],
      "metadata": {
        "id": "hYad5qTAa8uW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsUn-MewMBP0",
        "outputId": "165bcc60-89b2-4365-8daa-2daf30db6bd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database connection established successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sqlalchemy import create_engine\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the database URL from Colab secrets\n",
        "DATABASE_URL = userdata.get('POSTGRES_URL')\n",
        "\n",
        "# Create a database engine\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "print(\"Database connection established successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e58a4c2f",
        "outputId": "924e91f3-e015-498e-b837-86c206eb1a50"
      },
      "source": [
        "from sqlalchemy import inspect\n",
        "\n",
        "inspector = inspect(engine)\n",
        "\n",
        "# Get table names\n",
        "table_names = inspector.get_table_names()\n",
        "print(\"Tables in the database:\")\n",
        "for table_name in table_names:\n",
        "    print(f\"- {table_name}\")\n",
        "\n",
        "print(\"\\nColumns in each table:\")\n",
        "# Get column names for each table\n",
        "for table_name in table_names:\n",
        "    print(f\"\\nTable: {table_name}\")\n",
        "    columns = inspector.get_columns(table_name)\n",
        "    for column in columns:\n",
        "        print(f\"- {column['name']} ({column['type']})\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables in the database:\n",
            "- videos\n",
            "- alembic_version\n",
            "- video_metadata\n",
            "- transcripts\n",
            "- transcription_segments\n",
            "- transcription_chunks\n",
            "- embeddings\n",
            "- embeddings_cache\n",
            "- taggings\n",
            "- tags\n",
            "\n",
            "Columns in each table:\n",
            "\n",
            "Table: videos\n",
            "- video_id (VARCHAR(20))\n",
            "- url (VARCHAR(255))\n",
            "- title (VARCHAR(255))\n",
            "- description (TEXT)\n",
            "- published_at (TIMESTAMP)\n",
            "- created_at (TIMESTAMP)\n",
            "- updated_at (TIMESTAMP)\n",
            "- duration_seconds (INTEGER)\n",
            "\n",
            "Table: alembic_version\n",
            "- version_num (VARCHAR(32))\n",
            "\n",
            "Table: video_metadata\n",
            "- video_id (VARCHAR(20))\n",
            "- hebrew_date (VARCHAR(50))\n",
            "- subject (VARCHAR(500))\n",
            "- created_at (TIMESTAMP)\n",
            "- updated_at (TIMESTAMP)\n",
            "- day_of_week (VARCHAR(20))\n",
            "\n",
            "Table: transcripts\n",
            "- video_id (VARCHAR(20))\n",
            "- source (VARCHAR(20))\n",
            "- language (VARCHAR(10))\n",
            "- full_text (TEXT)\n",
            "- segments (JSONB)\n",
            "- created_at (TIMESTAMP)\n",
            "- updated_at (TIMESTAMP)\n",
            "\n",
            "Table: transcription_segments\n",
            "- id (INTEGER)\n",
            "- video_id (VARCHAR(20))\n",
            "- source (VARCHAR(20))\n",
            "- segment_index (INTEGER)\n",
            "- start (DOUBLE PRECISION)\n",
            "- duration (DOUBLE PRECISION)\n",
            "- end (DOUBLE PRECISION)\n",
            "- text (TEXT)\n",
            "- raw (JSONB)\n",
            "- created_at (TIMESTAMP)\n",
            "- updated_at (TIMESTAMP)\n",
            "\n",
            "Table: transcription_chunks\n",
            "- id (INTEGER)\n",
            "- video_id (VARCHAR(20))\n",
            "- source (VARCHAR(20))\n",
            "- first_segment_id (INTEGER)\n",
            "- last_segment_id (INTEGER)\n",
            "- start (DOUBLE PRECISION)\n",
            "- end (DOUBLE PRECISION)\n",
            "- created_at (TIMESTAMP)\n",
            "- updated_at (TIMESTAMP)\n",
            "- text (TEXT)\n",
            "\n",
            "Table: embeddings\n",
            "- id (INTEGER)\n",
            "- video_id (VARCHAR(20))\n",
            "- transcription_chunk_id (INTEGER)\n",
            "- kind (VARCHAR(50))\n",
            "- source_cache_id (INTEGER)\n",
            "- created_at (TIMESTAMP)\n",
            "- updated_at (TIMESTAMP)\n",
            "\n",
            "Table: embeddings_cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-614922236.py:15: SAWarning: Did not recognize type 'vector' of column 'vector'\n",
            "  columns = inspector.get_columns(table_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- id (INTEGER)\n",
            "- text (TEXT)\n",
            "- model (VARCHAR(128))\n",
            "- vector (NULL)\n",
            "- created_at (TIMESTAMP)\n",
            "- updated_at (TIMESTAMP)\n",
            "\n",
            "Table: taggings\n",
            "- id (INTEGER)\n",
            "- tag_id (INTEGER)\n",
            "- video_id (VARCHAR(20))\n",
            "- source (VARCHAR(100))\n",
            "- created_at (TIMESTAMP)\n",
            "- updated_at (TIMESTAMP)\n",
            "\n",
            "Table: tags\n",
            "- id (INTEGER)\n",
            "- name (VARCHAR(20))\n",
            "- description (TEXT)\n",
            "- type (VARCHAR(30))\n",
            "- created_at (TIMESTAMP)\n",
            "- updated_at (TIMESTAMP)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d352bb4c",
        "outputId": "0423962d-e035-4fbf-a98f-a15fa2e47870"
      },
      "source": [
        "from sqlalchemy.orm import sessionmaker\n",
        "from sqlalchemy import text\n",
        "\n",
        "# Define the VideoData class\n",
        "class VideoData:\n",
        "    def __init__(self, video_id, subject, gregorian_date, hebrew_date, subject_embedding, first_chunk_text, first_chunk_embedding):\n",
        "        self.video_id = video_id\n",
        "        self.subject = subject\n",
        "        self.gregorian_date = gregorian_date\n",
        "        self.hebrew_date = hebrew_date\n",
        "        self.subject_embedding = subject_embedding\n",
        "        self.first_chunk_text = first_chunk_text\n",
        "        self.first_chunk_embedding = first_chunk_embedding\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"VideoData(video_id={self.video_id}, subject='{self.subject}', gregorian_date='{self.gregorian_date}', hebrew_date='{self.hebrew_date}', first_chunk_text='{self.first_chunk_text[:50]}...')\"\n",
        "\n",
        "# Create a session to interact with the database\n",
        "Session = sessionmaker(bind=engine)\n",
        "session = Session()\n",
        "\n",
        "# Query the database to get the required video data\n",
        "video_data_list = []\n",
        "try:\n",
        "    query = text(\"\"\"\n",
        "        SELECT\n",
        "            vm.video_id,\n",
        "            vm.subject,\n",
        "            v.published_at AS gregorian_date,\n",
        "            vm.hebrew_date,\n",
        "            sec.vector AS subject_embedding,\n",
        "            tc.text AS first_chunk_text,\n",
        "            tcec.vector AS first_chunk_embedding\n",
        "        FROM video_metadata vm\n",
        "        JOIN videos v ON vm.video_id = v.video_id\n",
        "        JOIN embeddings se ON v.video_id = se.video_id AND se.transcription_chunk_id IS NULL\n",
        "        JOIN embeddings_cache sec ON se.source_cache_id = sec.id\n",
        "        JOIN (\n",
        "            SELECT\n",
        "                video_id,\n",
        "                MIN(first_segment_id) as min_first_segment_id\n",
        "            FROM transcription_chunks\n",
        "            GROUP BY video_id\n",
        "        ) as min_tc ON vm.video_id = min_tc.video_id\n",
        "        JOIN transcription_chunks tc ON vm.video_id = tc.video_id AND tc.first_segment_id = min_tc.min_first_segment_id\n",
        "        JOIN embeddings tce ON tc.id = tce.transcription_chunk_id AND tce.video_id = vm.video_id\n",
        "        JOIN embeddings_cache tcec ON tce.source_cache_id = tcec.id\n",
        "    \"\"\")\n",
        "\n",
        "    result = session.execute(query)\n",
        "\n",
        "    for row in result:\n",
        "        video_data = VideoData(\n",
        "            video_id=row.video_id,\n",
        "            subject=row.subject,\n",
        "            gregorian_date=row.gregorian_date,\n",
        "            hebrew_date=row.hebrew_date,\n",
        "            subject_embedding=row.subject_embedding,\n",
        "            first_chunk_text=row.first_chunk_text,\n",
        "            first_chunk_embedding=row.first_chunk_embedding\n",
        "        )\n",
        "        video_data_list.append(video_data)\n",
        "\n",
        "    print(f\"Successfully loaded {len(video_data_list)} videos.\")\n",
        "    # Display the first few entries to verify\n",
        "    for i in range(min(5, len(video_data_list))):\n",
        "        print(video_data_list[i])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "finally:\n",
        "    session.close()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 1011 videos.\n",
            "VideoData(video_id=_03R7gJHoKM, subject='אכילת פיתה שחוממה ע\"ג סיר בשרי עם מאכל חלבי', gregorian_date='2022-12-14 21:35:45+00:00', hebrew_date='כ\"ה כסלו התשפ\"ג', first_chunk_text='שלום רב אחד מבני הבית רצה לחמם פיתה על גבי הסיר שנ...')\n",
            "VideoData(video_id=_19uanvcg30, subject='מהי ברכת הריח על ציפורן וקינמון?', gregorian_date='2025-05-03 21:31:16+00:00', hebrew_date='ו' אייר התשפ\"ה', first_chunk_text='‫שלום רב. יום ראשון, וב ואייר. ‫מהי ברכת הריח שמבר...')\n",
            "VideoData(video_id=_AlfP4rDA1k, subject='דבר תורה לפרשת 'וישלח'', gregorian_date='2023-11-30 22:11:51+00:00', hebrew_date='י\"ח כסלו התשפ\"ד', first_chunk_text='‫שלום רב. יום שישי יותחת כסלב, ‫ערב שבת קודש פרשת ...')\n",
            "VideoData(video_id=_d1Ag4AvoSY, subject='אדם שטעה ושתה בתענית האם יברך ברכה אחרונה?', gregorian_date='2022-07-24 09:38:48+00:00', hebrew_date='ו' אב התשפ\"ב', first_chunk_text='שלום רב נשאלתי שאלה מעניינת בתענית האחרונה של יהוד...')\n",
            "VideoData(video_id=_dwr1xhkVTE, subject='לברך ברכות השחר בבוקר טרם נפנה לנקביו', gregorian_date='2022-11-23 21:48:57+00:00', hebrew_date='ז' כסלו התשפ\"ג', first_chunk_text='שלום רב כידוע לכם חכמנו זכולם לברכה תקנו שאסור לאד...')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbe66f7e"
      },
      "source": [
        "Now that the video data is loaded, we need to extract the embedding vectors. We will create two NumPy arrays: one for the subject embeddings and one for the first chunk embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "713e7eff",
        "outputId": "76c5300b-6026-4572-9662-17fa72fc8fb2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "subject_embeddings = []\n",
        "first_chunk_embeddings = []\n",
        "video_ids = [] # Store video_ids to link embeddings back to videos\n",
        "\n",
        "for video_data in video_data_list:\n",
        "    # Since we used JOINs, we expect these to be non-None\n",
        "    subject_embeddings.append(video_data.subject_embedding)\n",
        "    video_ids.append(video_data.video_id) # Append video_id for each subject embedding\n",
        "    first_chunk_embeddings.append(video_data.first_chunk_embedding)\n",
        "\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "subject_embeddings_array = np.array(subject_embeddings)\n",
        "first_chunk_embeddings_array = np.array(first_chunk_embeddings)\n",
        "video_ids_array = np.array(video_ids)\n",
        "\n",
        "\n",
        "print(f\"Extracted {len(subject_embeddings)} subject embeddings.\")\n",
        "print(f\"Subject embeddings array shape: {subject_embeddings_array.shape}\")\n",
        "print(f\"Extracted {len(first_chunk_embeddings)} first chunk embeddings.\")\n",
        "print(f\"First chunk embeddings array shape: {first_chunk_embeddings_array.shape}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 1011 subject embeddings.\n",
            "Subject embeddings array shape: (1011,)\n",
            "Extracted 1011 first chunk embeddings.\n",
            "First chunk embeddings array shape: (1011,)\n"
          ]
        }
      ]
    }
  ]
}